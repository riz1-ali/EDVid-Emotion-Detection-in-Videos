{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from keras.models import load_model\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from https://github.com/vjgpt/Face-and-Emotion-Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, grayscale=False, target_size=None):\n",
    "    pil_image = image.load_img(image_path, grayscale, target_size)\n",
    "    return image.img_to_array(pil_image)\n",
    "\n",
    "def load_detection_model(model_path):\n",
    "    detection_model = cv2.CascadeClassifier(model_path)\n",
    "    return detection_model\n",
    "\n",
    "def detect_faces(detection_model, gray_image_array):\n",
    "    return detection_model.detectMultiScale(gray_image_array, 1.3, 5)\n",
    "\n",
    "def draw_bounding_box(face_coordinates, image_array, color):\n",
    "    x, y, w, h = face_coordinates\n",
    "    cv2.rectangle(image_array, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "def apply_offsets(face_coordinates, offsets):\n",
    "    x, y, width, height = face_coordinates\n",
    "    x_off, y_off = offsets\n",
    "    return (x - x_off, x + width + x_off, y - y_off, y + height + y_off)\n",
    "\n",
    "def draw_text(coordinates, image_array, text, color, x_offset=0, y_offset=0,\n",
    "                                                font_scale=0.5, thickness=1):\n",
    "    x, y = coordinates[:2]\n",
    "    #cv2.rectangle(image_array, (x + 60, y + y_offset),(x + x_offset, y + y_offset-15), (255, 255, 255), cv2.FILLED)\n",
    "    cv2.putText(image_array, text, (x + x_offset, y + y_offset),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def get_colors(num_classes):\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, num_classes)).tolist()\n",
    "    colors = np.asarray(colors) * 255\n",
    "    return colors\n",
    "\n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x\n",
    "\n",
    "def _imread(image_name):\n",
    "        return cv.imread(image_name)\n",
    "\n",
    "def _imresize(image_array, size):\n",
    "        return cv.resize(image_array, size)\n",
    "\n",
    "def to_categorical(integer_classes, num_classes=2):\n",
    "    integer_classes = np.asarray(integer_classes, dtype='int')\n",
    "    num_samples = integer_classes.shape[0]\n",
    "    categorical = np.zeros((num_samples, num_classes))\n",
    "    categorical[np.arange(num_samples), integer_classes] = 1\n",
    "    return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model_path = './model.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {0:'angry',1:'disgust',2:'fear',3:'happy',\n",
    "                4:'sad',5:'surprise',6:'neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizwan/anaconda3/envs/acads/lib/python3.6/site-packages/keras/engine/saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "frame_window = 10\n",
    "emotion_offsets = (20, 40)\n",
    "\n",
    "# loading models\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "emotion_classifier = load_model(emotion_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "\n",
    "# starting lists for calculating modes\n",
    "emotion_window = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"./testvdo.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "surprise\n",
      "fear\n",
      "happy\n",
      "surprise\n",
      "happy\n",
      "surprise\n",
      "surprise\n",
      "happy\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "neutral\n",
      "neutral\n",
      "angry\n",
      "angry\n",
      "fear\n",
      "happy\n",
      "sad\n",
      "fear\n",
      "sad\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "surprise\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "sad\n",
      "surprise\n",
      "angry\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "surprise\n",
      "happy\n",
      "surprise\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "surprise\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "surprise\n",
      "happy\n",
      "sad\n",
      "surprise\n",
      "happy\n",
      "sad\n",
      "surprise\n",
      "happy\n",
      "sad\n",
      "surprise\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "angry\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "happy\n",
      "sad\n",
      "sad\n",
      "happy\n",
      "happy\n",
      "neutral\n",
      "happy\n",
      "angry\n",
      "happy\n",
      "neutral\n",
      "happy\n",
      "neutral\n",
      "sad\n",
      "neutral\n",
      "sad\n",
      "neutral\n",
      "sad\n",
      "angry\n",
      "neutral\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "sad\n",
      "angry\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "sad\n",
      "neutral\n",
      "sad\n",
      "neutral\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "happy\n",
      "angry\n",
      "angry\n",
      "sad\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "fear\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "sad\n",
      "fear\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "angry\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n",
      "sad\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-33ed5085208a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgray_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mrgb_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.2.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "            break\n",
    "    gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    faces = detector(rgb_image)\n",
    "    for face_coordinates in faces:\n",
    "        x1, x2, y1, y2 = apply_offsets(face_utils.rect_to_bb(face_coordinates), emotion_offsets)\n",
    "        gray_face = gray_image[y1:y2, x1:x2]\n",
    "        try:\n",
    "            gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        gray_face = preprocess_input(gray_face, True)\n",
    "        gray_face = np.expand_dims(gray_face, 0)\n",
    "        gray_face = np.expand_dims(gray_face, -1)\n",
    "        emotion_prediction = emotion_classifier.predict(gray_face)\n",
    "        emotion_probability = np.max(emotion_prediction)\n",
    "        emotion_label_arg = np.argmax(emotion_prediction)\n",
    "        emotion_text = labels[emotion_label_arg]\n",
    "        \n",
    "        print(emotion_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
